train:
  log_name: cutmix_2layer
  back_freeze: False
  load_model: False
  epochs: 100
  n_folds: 5
  n_gpus: 2
  single_model: False
  single_fold: 1
  cutmix: False
#  seed: 3407
  seed: 12
  precision: 16
  lr: 0.001

  fold_random_state: 49

  # seed paper(https://arxiv.org/pdf/2109.08203.pdf) abt 3407

model:
  backbone:
    model_name: swin_large_patch4_window12_384
    pretrained: True
    num_classes: 0
    in_chans: 3

  head:
    out_dim_reg: 1 # regression

  loss:
    reg: nn.BCEWithLogitsLoss
    elastic:
      l1_ratio: 0.5
      alpha: 1

  auto_opt: True

  optimizer:
    momentum: 0.09
    nesterov: True

  scheduler:
    OneCycleLR:
      steps_per_epoch: 520 #130 for 32batch
      epochs: 1
      #    total_steps: 143
      max_lr: 0.025
      verbose: False

    CyclicLR:
      base_lr: 0.0001
      max_lr: 0.001
      step_size_up: 80
      step_size_down: 160
      cycle_momentum: True

    Plateau:
      mode: min
      factor: 0.31
      patience: 2
      min_lr: 0.000001
      verbose: True

    CosineAnnealingLR:
      T_max: 300
      eta_min: 0.0001

# legacy


#   legacy
#  CyclicLR:
#    base_lr: 0.000001
#    max_lr: 0.0002
#    step_size_up: 20
#    step_size_down: 40
#    cycle_momentum: False


early_stopper:
  patience: 10

transform:
  name: get_default_transforms
  image_size: 384

train_loader:
  batch_size: 8
  shuffle: False
#  batch_size: 1
#  shuffle: False
  num_workers: 4
  pin_memory: True
  drop_last: False

valid_loader:
  batch_size: 8
  drop_last: False
  num_workers: 4
  pin_memory: False
  shuffle: False

test_loader:
  batch_size: 1
  shuffle: False
  num_workers: 4
  pin_memory: False
  drop_last: False
